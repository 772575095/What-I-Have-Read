# What I Have Read

> Read papers in other fields whenever possible.
> Read papers from other conferences whenever possible.
> Read as many papers as possible.

* [What I Have Read](#what-i-have-read)
  * [Slides](#slides)
     * [Presentation](#presentation)
     * [Paper slides](#paper-slides)
     * [Notes](#notes)
  * [Summarization Papers](#summarization-papers)
  * [Meta Learning Papers](#meta-learning-papers)
  * [Graph Neural Networks (GNN)](#graph-neural-networks-gnn)
  * [Generative Adversarial Networks (GAN)](#generative-adversarial-networks-gan)
  * [Knowledge Distillation](#knowledge-distillation)
  * [Pre-train Based](#pre-train-based)
  * [Multi Modal](#multi-modal)
  * [Blogs](#blogs)

  
## Slides
### Presentation

* [Meta Learning](slides/presentation/Meta%20Learning.pdf)
* [Advanced pre-training language models a brief introduction](slides/presentation/Advanced%20pre-training%20language%20models%20a%20brief%20introduction.pdf)
* [Graph Neural Networks](slides/presentation/Graph%20Neural%20Networks.pdf)

### Paper slides
* [ACL19-Dynamically Fused Graph Network for Multi-hop Reasoning](slides/paper-slides/Dynamically%20Fused%20Graph%20Network%20for%20Multi-hop%20Reasoning.pdf)
* [NAACL19-Linguistic Knowledge and Transferability of Contextual Representations](slides/paper-slides/Linguistic%20Knowledge%20and%20Transferability%20of%20Contextual%20Representations.pdf)
* [NAACL19-Text Generation from Knowledge Graphs with Graph Transformers](slides/paper-slides/Text%20Generation%20from%20Knowledge%20Graphs%20with%20Graph%20Transformers.pdf)
* [The Curious Case of Neural Text Degeneration ](slides/paper-slides/The%20Curious%20Case%20of%20Neural%20Text%20Degeneration.pdf)
* [EMNLP18-Multi-Domain Neural Machine Translation with Word-Level Domain Context Discrimination](slides/paper-slides/Multi-Domain%20Neural%20Machine%20Translation%20with%20Word-Level%20Domain%20Context%20Discrimination.pdf)
* [EMNLP18-Commonsense for Generative Multi-Hop Question Answering Tasks](slides/paper-slides/Commonsense%20for%20Generative%20Multi-Hop%20Question%20Answering%20Tasks.pdf)
* [IJCAI18-Commonsense Knowledge Aware Conversation Generation with Graph Attention](slides/paper-slides/Commonsense%20Knowledge%20Aware%20Conversation%20Generation%20with%20Graph%20Attention.pdf)
* [AAAI18-Emotional Chatting Machine Emotional Conversation Generation with Internal and External Memory](slides/paper-slides/Emotional%20Chatting%20Machine%20Emotional%20Conversation%20Generation%20with%20Internal%20and%20External%20Memory.pdf)
* [EMNLP18-Learning Neural Templates for Text Generation](slides/paper-slides/Learning%20Neural%20Templates%20for%20Text%20Generation.pdf)
* [ACL18-Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders ](slides/paper-slides/Learning%20to%20Ask%20Questions%20in%20Open-domain%20Conversational%20Systems%20with%20Typed%20Decoders%20.pdf)
* [ACL17-Semi-Supervised QA with Generative Domain-Adaptive Nets](slides/paper-slides/Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets.pdf)
* [ACL17-Deep Multitask Learning for Semantic Dependency Parsing](slides/paper-slides/Deep%20Multitask%20Learning%20for%20Semantic%20Dependency%20Parsing.pdf)

### Notes
* [GAN in Text Generation](slides/notes/GAN%20in%20Text%20Generation.pdf)
* [Boosting](slides/notes/Boosting.pdf)
* [HMM](slides/notes/HMM.pdf)
* [The Maximum Entropy Model](slides/notes/The%20Maximum%20Entropy%20Model.pdf)
  

## Summarization Papers


### Multi-Document
| Paper | Conference |
| :---: | :---: |
|Improving the Similarity Measure of Determinantal Point Processes for Extractive Multi-Document Summarization|ACL19|
| Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model | ACL19 |
| Hierarchical Transformers for Multi-Document Summarization | ACL19 |
| MeanSum : A Neural Model for Unsupervised Multi-Document Abstractive Summarization|ICML19|
| Graph-based Neural Multi-Document Summarization|CoNLL17|
| Improving Multi-Document Summarization via Text Classification|AAAI17|
|Event-Centric Summary Generation| |

### Cross-Lingual
| Paper | Conference |
| :---: | :---: |
| A Robust Abstractive System for Cross-Lingual Summarization|NAACL19|

### Pre-train Based
| Paper | Conference |
| :---: | :---: |
|HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization|ACL19|
| MASS: Masked Sequence to Sequence Pre-training for Language Generation|ICML19|
| Pretraining-Based Natural Language Generation for Text Summarization||
| Fine-tune BERT for Extractive Summarization||
| Unified Language Model Pre-training for Natural Language Understanding and Generation||
|Self-Supervised Learning for Contextualized Extractive Summarization|ACL19|


### Unsupervised
| Paper | Conference |
| :---: | :---: |
| Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking | ACL19 |
| MeanSum : A Neural Model for Unsupervised Multi-Document Abstractive Summarization|ICML19|


### Dataset
| Paper | Conference |
| :---: | :---: |
| Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model | ACL19 |
| NEWSROOM: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies||
| TALKSUMM: A Dataset and Scalable Annotation Method for Scientiﬁc Paper Summarization Based on Conference Talks | ACL19 |
| BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization  | ACL19 |
| ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scientiﬁc Paper Summarization with Citation Networks | AAAI19 |
| Abstractive Summarization of Reddit Posts with Multi-level Memory Networks|NAACL19|
| Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization|EMNLP18|
| How2: A Large-scale Dataset for Multimodal Language Understanding|NIPS18|
| Abstractive Text Summarization by Incorporating Reader Comments|AAAI19|
| Generating Wikipedia By Summarizing Long Sequence | ICLR18 |

### Multi-modal
| Paper | Conference |
| :---: | :---: |
| How2: A Large-scale Dataset for Multimodal Language Understanding|NIPS18|
| Multimodal Abstractive Summarization for How2 Videos | ACL19 |

### Meeting 
| Paper | Conference |
| :---: | :---: |
| Abstractive Meeting Summarization via Hierarchical Adaptive Segmental Network Learning|WWW19|

### Related
| Paper | Conference |
| :---: | :---: |
| Growing Story Forest Online from Massive Breaking News|CIKM17|

| Paper | Conference |
| :---: | :---: |
|Generating Summaries with Topic Templates and Structured Convolutional Decoders|ACL19|
|Sentence Centrality Revisited for Unsupervised Summarization|ACL19|
|BiSET: Bi-directional Selective Encoding with Template for Abstractive Summarization|ACL19|
| HIGHRES: Highlight-based Reference-less Evaluation of Summarization | ACL19 |
| Searching for Effective Neural Extractive Summarization: What Works and What's Next | ACL19 |
|Generating Summaries with Topic Templates and Structured Convolutional Decoders|ACL19|
| Scoring Sentence Singletons and Pairs for Abstractive Summarization|ACL19|
| Guiding Extractive Summarization with Question-Answering Rewards|NAACL19|
|Single Document Summarization as Tree Induction|NAACL19|
| Jointly Extracting and Compressing Documents with Summary State Representations|NAACL19|
| Structured Neural Summarization|ICLR19|
| DeepChannel: Salience Estimation by Contrastive Learning for Extractive Document Summarization|AAAI19|
| Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization|ACL18|
| Extractive Summarization with SWAP-NET: Sentences and Words from Alternating Pointer Networks|ACL18|
| Neural Latent Extractive Document Summarization|ACL18|
| Soft Layer-Specific Multi-Task Summarization with Entailment and Question Generation|ACL18|
| Reinforced Extractive Summarization with Question-Focused Rewards|ACL18|
| A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss|ACL18|
| Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting|ACL18|
| Neural Document Summarization by Jointly Learning to Score and Select Sentences|ACL18|
| Controllable Abstractive Summarization|ACL2018 Workshop|
| Entity Commonsense Representation for Neural Abstractive Summarization | NAACL18|
| Multi-Reward Reinforced Summarization with Saliency and Entailment|NAACL18|
| Entity Commonsense Representation for Neural Abstractive Summarization | NAACL18 |
| Guiding Generation for Abstractive Text Summarization based on Key Information Guide Network|NAACL18|
| Ranking Sentences for Extractive Summarization with Reinforcement Learning|NAACL18|
| A Deep Reinforced Model For Abstractive Summarization|ICLR18|
| A Semantic QA-Based Approach for Text Summarization Evaluation|AAAI18|
| Generative Adversarial Network for Abstractive Text Summarization|AAAI18|
| Content Selection in Deep Learning Models of Summarization|EMNLP18|
| Improving Neural Abstractive Document Summarization with Explicit Information Selection Modeling|EMNLP18|
| Improving Neural Abstractive Document Summarization with Structural Regularization|EMNLP18|
| Closed-Book Training to Improve Summarization Encoder Memory|EMNLP18|
| Bottom-Up Abstractive Summarization|EMNLP18|
| Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization|EMNLP18|
| Get To The Point: Summarization with Pointer-Generator Networks|ACL17|
| Abstractive Document Summarization with a Graph-Based Attentional Neural Model|ACL17|
| Extractive Summarization Using Multi-Task Learning with Document Classification|EMNLP17| 
| SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents|AAAI17|
| Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond|CoNLL16|
| A Neural Attention Model for Abstractive Sentence Summarization|EMNLP15|
| Toward Abstractive Summarization Using Semantic Representations|NAACL15|
| Abstractive Meeting Summarization with Entailment and Fusion||
| Text Summarization through Entailment-based Minimum Vertex Cover||


## Meta Learning Papers
| Paper | Conference |
| :---: | :---: |
|Hierarchically Structured Meta-learning|ICML19|
|Personalizing Dialogue Agents via Meta-Learning|ACL19|
|Domain Adaptive Dialog Generation via Meta Learning|ACL19|
|Meta-Learning for Low-Resource Neural Machine Translation|EMNLP18|
|Natural Language to Structured Query Generation via Meta-Learning|NAACL18|
|Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks|ICML17|
|Optimization as a model for few-shot learning|ICLR17|

## Graph Neural Networks (GNN)
| Paper | Conference |
| :---: | :---: |
|Matching Article Pairs with Graphical Decomposition and Convolutions|ACL19|
|Dynamically Fused Graph Network for Multi-hop Reasoning|ACL19|
|Cognitive Graph for Multi-Hop Reading Comprehension at Scale|ACL19|
|Graph Neural Networks: A Review of Methods and Applications||
|Text Generation from Knowledge Graphs with Graph Transformers|NAACL19|
|Structural Neural Encoders for AMR-to-text Generation|NAACL19|
|Structured Neural Summarization|ICLR18|
|Graph-based Neural Multi-Document Summarization|CoNLL17|
|Graph-to-Sequence Learning using Gated Graph Neural Networks|ACL18|
|A Graph-to-Sequence Model for AMR-to-Text Generation|ACL18|
|SQL-to-Text Generation with Graph-to-Sequence Model|EMNLP18|


## Generative Adversarial Networks (GAN)

| Paper | Name | Conference |
| :---: | :---: | :---: |
|RELGAN: RELATIONAL GENERATIVE ADVERSARIAL NETWORKS FOR TEXT GENERATION|RelGAN|ICLR19|


## Knowledge Distillation
| Paper | Conference |
| :---: | :---: |
|Distilling Task-Speciﬁc Knowledge from BERT into Simple Neural Networks||
|Exploiting the Ground-Truth: An Adversarial Imitation Based Knowledge Distillation Approach for Event Detection|AAAI19|
|On-Device Neural Language Model based Word Prediction|COLING18|
|Cross-lingual Distillation for Text Classiﬁcation|ACL17|
|Sequence-Level Knowledge Distillation|EMNLP16|




## Pre-train Based
| Paper | Conference |
| :---: | :---: |
|XLNet: Generalized Autoregressive Pretraining for Language Understanding||
|Pre-Training with Whole Word Masking for Chinese BERT||
|Unified Language Model Pre-training for Natural Language Understanding and Generation||
|ERNIE: Enhanced Representation through Knowledge Integration||
|ERNIE: Enhanced Language Representation with Informative Entities|ACL19|
|MASS: Masked Sequence to Sequence Pre-training for Language Generation|ICML19|
| BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|NAACL19|
|Linguistic Knowledge and Transferability of Contextual Representations|NAACL19|
|Improving Language Understanding by Generative Pre-Training||
|Deep contextualized word representations|NAACL18|


## Multi Modal
| Paper | Conference |
| :---: | :---: |
|VATEX:A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research||
|Multimodal Abstractive Summarization for How2 Videos|ACL19|
|How2:A Large-scale Dataset for Multimodal Language Understanding|NIPS18|


## Blogs
* [The Why, When, and How of Using Python Multi-threading and Multi-Processing](https://medium.com/towards-artificial-intelligence/the-why-when-and-how-of-using-python-multi-threading-and-multi-processing-afd1b8a8ecca)























