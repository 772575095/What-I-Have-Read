# Cross-Lingual

| Paper | Conference |
| :---: | :---: |
| A survey of cross-lingual word embeddingmodels||
| How multilingual is Multilingual BERT?|ACL19|
| From Bilingual to Multilingual Neural Machine Translation by Incremental Training | ACL19 |
| Cross-Lingual Training for Automatic Question Generation | ACL19 |
| Multilingual Unsupervised NMT using Shared Encoder and Language-Speciﬁc Decoders|ACL19|
| Cross-lingual Language Model Pretraining||
| Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT||
| BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|NAACL19|
|Transfer Learning in Multilingual Neural Machine Translation with Dynamic Vocabulary|IWSLT18|
| UNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY|ICLR18|
| WORD TRANSLATION WITHOUT PARALLEL DATA|ICLR18|
| Zero-shot cross-lingualneural headline generation|IEEE|
| Phrase-Based & Neural Unsupervised Machine Translation|EMNLP18|
| Learning Crosslingual Word Embeddings without Bilingual Corpora|EMNLP16|
| Massively Multilingual Word Embeddings||
| Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation ||
| Simple task-speciﬁc bilingual word embeddings|NAACL15|
| Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation|NAACL15|
| Distributed Word Representation Learning for Cross-Lingual Dependency Parsing|ACL14|
| Exploiting Similarities among Languages for Machine Translation||


