# Knowledge Distillation

| Paper | Conference |
| :---: | :---: |
|Distilling Task-Speciﬁc Knowledge from BERT into Simple Neural Networks||
|Exploiting the Ground-Truth: An Adversarial Imitation Based Knowledge Distillation Approach for Event Detection|AAAI19|
|On-Device Neural Language Model based Word Prediction|COLING18|
|Cross-lingual Distillation for Text Classiﬁcation|ACL17|
|Sequence-Level Knowledge Distillation|EMNLP16|


